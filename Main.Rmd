---
title: '[ENSAE, 2A] Séminaire statistique 2023'
author: "Hassan Maissoro/ Léa Joly / Antoine Klein"
date: "2023-03-17"
output:
  html_document:
    toc: yes
    toc_depth: 4
    number_sections: yes
    theme: readable
    highlight: tango
    toc_float:
      collapsed: no
      smooth_scroll: no
    css: style.css
    fig_width: 8
    fig_height: 3
  pdf_document:
    toc: yes
    toc_depth: '4'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

<p id="p_">

<b> Sujet : Modélisation de la production d'électricité d'un barrage </b>

</p>

Objectif : Prédire la production d'électricité pour le lendemain compte tenu de la production passée

# On installe les packages

```{r}
install.packages("manipulateWidget")
install.packages("tseries")
install.packages("zoo")
install.packages("dygraphs")
install.packages('pls')
install.packages("forecast", dependencies = TRUE)# Pour établir des prédictions
install.packages("ggplot2") # Pour les plots
install.packages("fUnitRoots")# Tests de racine unitaire
```

# On importe les packages

```{r}
library(data.table)
library(magrittr)
library(dygraphs)
library(manipulateWidget)
library(pls)
require(zoo) #format de serie temporelle pratique et facile d'utilisation 
require(tseries) #diverses fonctions sur les series temporelles
library(forecast)
library(ggplot2)
library(fUnitRoots)
```

# Données

Les données utilisées dans le cadre de ce séminaire ont été simulées. On se concentre sur un seul barrage hydroélectrique.

-   `date` : date d'observation de la mesure.
-   `y` : production électrique du barrage.
-   `x` : hauteur du cours sur lequel est implanté le barrage, mesurée par une station placée en amont du barrage.

```{r fig.width=8, fig.height=5, fig.align='center'}
#On change le path
path <- "~/work/ENSAE_Seminaire_Stat"
setwd(path) #definit l'espace de travail (working directory ou "wd")
getwd() #affiche le wd
# Import des données
dt <- readRDS("./data.RDS")

# Visualisation
gy <- dygraph(data = dt[, .(date, y)],main = "Production électrique",
              xlab = "date", ylab = "y", group = "rowData") %>% 
  dyOptions(colors = "blue")
gx <- dygraph(data = dt[, .(date, x)],main = "Hauteur du cours d'eau",
              xlab = "date", ylab = "x", group = "rowData")%>% 
  dyOptions(colors = "green")

manipulateWidget::combineWidgets(list = list(gy, gx), nrow = 2)
```

# Modélisation

*Objectif :* Améliorer la méthode initiale.

*Questions :*

-   Comment faire un découpage train/test lorsque les données sont temporelles ?
-   Comment faire une validation croisée sur des séries temporelles ?

*Choix du coupage train/test :*

```{r}
dt[, range(date)]
```

-   train sur 2021 - 2022 ;
-   test sur 2023.

*Horizon de prévision :* on se concentre sur l'horizon : **J+1**.

*Mesure d'erreur de prévision :*

```{r}
get_rmse <- function(y_true, y_prev){
  sqrt(mean( (y_true - y_prev) ** 2 ))
}
```

## Méthode à améliorer

La méthode initialement implémentée consiste à faire la moyenne des 4 derniers jours.

```{r}
# Crée des variables lag
lag_names <- paste0("y_lag_", 1:4)
dt_prev <- copy(dt)

dt_prev[, c(lag_names) := shift(x = y, n = 1:4, type = "lag")]
dt_prev <- na.omit(dt_prev)

# On calcule les prévisions
dt_prev[, prev := rowMeans(.SD), .SDcols = lag_names]

# Prévision
dt_init_prev <- dt_prev[year(date) <= 2022, prev := NA]
```

```{r}
dt_init_prev
```

```{r}
rmse_init <- get_rmse(y_true = dt_init_prev[ !is.na(prev), y],
                      y_prev = dt_init_prev[ !is.na(prev), prev])
rmse_init
```


```{r fig.width=8, fig.height=3, fig.align='center'}
dygraphs::dygraph(data = dt_init_prev[, .(date, y, prev)], main = "prev vs true") %>% 
  dygraphs::dySeries(name = "prev", color = "red")
```

## Améliorations

### Ajout de covariables

Les covariables peuvent être des :

-   retards de `y` ;
-   retards de `x` ;
-   agrégats de retards `y` et/ou de `x`.

```{r}
## Ajout de lag de x et de y
dt_model <- copy(dt)
dt_model[, c(paste0("y_lag_", 1:14)) := shift(x = y, n = 1:14, type = "lag")]
dt_model[, c(paste0("x_lag_", 1:14)) := shift(x = x, n = 1:14, type = "lag")]
dt_model <- na.omit(dt_model)
```

```{r}
dt_train <- dt_model[year(date) <= 2022]
dt_test <- dt_model[year(date) > 2022]
```


### PLS

Régression des moindres carrés partiels (PLS). Le nombre de composantes à conserver est déterminé par validation croisée sur les données d'apprentissage. Référence : [cliquer ici](https://www.math.univ-toulouse.fr/~besse/Wikistat/pdf/st-m-app-sparse-pls.pdf) ;

-   PLS que sur les retards de la production `y` ;

```{r}
ylag <- paste0("y_lag_", 1:14)

## Estimation du modèle
pls_prod <- pls::plsr(formula = y ~ .,
                      data = dt_train[, .SD, .SDcols = c("y", ylag)],
                      validation = "CV")
## Take optimal ncomp
rmsepcv.pls <- pls::MSEP(pls_prod, estimate = 'CV')
ncp.optim <- which.min(rmsepcv.pls$val["CV", , ]) - 1
ncp.optim <- ifelse(ncp.optim == 0, 1, ncp.optim)

# prevision
prev_pls <- predict(object = pls_prod, newdata = dt_test, ncomp = ncp.optim)

## On borne les prévisions si elles sont inférieures à 0
prev_pls <- ifelse(prev_pls[, 1, 1] < 0, 0, prev_pls[, 1, 1])
prev_pls <- unname(prev_pls)
```

```{r}
ncp.optim
```


```{r}
rmse_pls <- get_rmse(y_true = dt_test[, y], y_prev = prev_pls)
rmse_pls
```
Cette rmse est inférieure à la rmse initiale (273.5126 < 304.3409)

```{r fig.width=8, fig.height=3, fig.align='center'}
dt_prev_pls <- rbind(
  copy(dt_test)[, .(date, y)][, prev_pls := prev_pls],
  copy(dt_train)[, .(date, y)][, prev_pls := NA]
)

dygraphs::dygraph(data = dt_prev_pls, main = "PLS - prev vs true") %>% 
  dygraphs::dySeries(name = "prev_pls", color = "red")
```
### ajout des retards en x
```{r}
# Ajout des covariables x
xlag <- paste0("x_lag_", 1:14) # ajout des retards de x
lags <- c(xlag, ylag)    # on combine les retards de x et y

# Estimation du modèle
pls_prod2 <- pls::plsr(formula = y ~ .,
                      data = dt_train[, .SD, .SDcols = c("y", lags)],
                      validation = "CV")

# Take optimal ncomp
rmsepcv.pls2 <- pls::MSEP(pls_prod2, estimate = 'CV')
ncp.optim2 <- which.min(rmsepcv.pls2$val["CV", , ]) - 1
ncp.optim2 <- ifelse(ncp.optim2 == 0, 1, ncp.optim2)

# Prévision
prev_pls2 <- predict(object = pls_prod2, newdata = dt_test, ncomp = ncp.optim2)

# On borne les prévisions si elles sont inférieures à 0
prev_pls2 <- ifelse(prev_pls2[, 1, 1] < 0, 0, prev_pls2[, 1, 1])
prev_pls2 <- unname(prev_pls2)
```

```{r}
ncp.optim2
```
```{r}
rmse_pls2 <- get_rmse(y_true = dt_test[, y], y_prev = prev_pls2)
rmse_pls2
```
Cette rmse est supérieure à la rmse de la PLS avec uniquement les retards de y (273.5126 < 282.1821), il n'a donc pas d'amélioration de la prédiction. Cela peut avoir plusieurs explications : 

- Les retards de x n'ont pas de lien avec la variable cible y : leur introduction ne contribue pas à améliorer les prévisions. Au contraire, les retards de x peuvent introduire du bruit dans le modèle et conduire à des prévisions de moins bonne qualité.

-Les retards de x sont fortement corrélés avec d'autres variables explicatives (ici les retards de y) : Si les retards de x sont fortement corrélés avec les retards de y, cela peut entraîner un effet de multi-collinéarité dans le modèle PLS. Cela peut rendre difficile pour le modèle de déterminer quels coefficients attribuer à chaque variable explicative, ce qui peut entraîner des prévisions moins précises.

```{r fig.width=8, fig.height=3, fig.align='center'}
dt_prev_pls2 <- rbind(
  copy(dt_test)[, .(date, y)][, prev_pls2 := prev_pls2],
  copy(dt_train)[, .(date, y)][, prev_pls2 := NA]
)

dygraphs::dygraph(data = dt_prev_pls2, main = "PLS2 - prev vs true") %>% 
  dygraphs::dySeries(name = "prev_pls2", color = "red")
```
### ajout des agrégats de lags

```{r}
# Ajout des agrégats de retards de x et y

# ajout des moyennes mobiles pour les retards de x
x_mean_lag <- paste0("x_mean_lag_", 1:14)
dt_train[, (x_mean_lag) := lapply(.SD, zoo::rollmean, k=3, fill=NA, align="right"), .SDcols = xlag]

# ajout des moyennes mobiles pour les retards de y
y_mean_lag <- paste0("y_mean_lag_", 1:14)
dt_train[, (y_mean_lag) := lapply(.SD, zoo::rollmean, k=3, fill=NA, align="right"), .SDcols = ylag]

dt_train <- na.omit(dt_train)

lags <- c(xlag, ylag, x_mean_lag, y_mean_lag) # on combine les retards de x, y et les moyennes mobiles

# Estimation du modèle
pls_prod3 <- pls::plsr(formula = y ~ .,
                      data = dt_train[, .SD, .SDcols = c("y", lags)],
                      validation = "CV")

# Take optimal ncomp
rmsepcv.pls3 <- pls::MSEP(pls_prod3, estimate = 'CV')
ncp.optim3 <- which.min(rmsepcv.pls3$val["CV", , ]) - 1
ncp.optim3 <- ifelse(ncp.optim3 == 0, 1, ncp.optim3)

# Ajout des moyennes mobiles pour les retards de x dans les données de test
dt_test[, (x_mean_lag) := lapply(.SD, zoo::rollmean, k=3, fill=NA, align="right"), .SDcols = xlag]

# Ajout des moyennes mobiles pour les retards de y dans les données de test
dt_test[, (y_mean_lag) := lapply(.SD, zoo::rollmean, k=3, fill=NA, align="right"), .SDcols = ylag]

dt_test <- na.omit(dt_test)

# Prévision
prev_pls3 <- predict(object = pls_prod3, newdata = dt_test[, lags, with=FALSE], ncomp = ncp.optim3)

# On borne les prévisions si elles sont inférieures à 0
prev_pls3 <- ifelse(prev_pls3[, 1, 1] < 0, 0, prev_pls3[, 1, 1])
prev_pls3 <- unname(prev_pls3)
```

```{r}
ncp.optim3
```
```{r}
rmse_pls3 <- get_rmse(y_true = dt_test[, y], y_prev = prev_pls3)
rmse_pls3
```
Cette rmse est supérieure aux rmse des 2 autres PLS (PLS1 : 273.5126 < PLS2 : 282.1821 < PLS3 : 283.5689), il n'y a donc pas d'amélioration de la prédiction.


```{r fig.width=8, fig.height=3, fig.align='center'}
dt_prev_pls3 <- rbind(
  copy(dt_test)[, .(date, y)][, prev_pls3 := prev_pls3],
  copy(dt_train)[, .(date, y)][, prev_pls3 := NA]
)

dygraphs::dygraph(data = dt_prev_pls3, main = "PLS3 - prev vs true") %>% 
  dygraphs::dySeries(name = "prev_pls3", color = "red")
```



### Regression LS

```{r}
# Estimation du modèle
lm_prod <- lm(y ~ ., data = dt_train[, .SD, .SDcols = c("y", ylag)])

# Prévision
prev_lm <- predict(object = lm_prod, newdata = dt_test)

# On borne les prévisions si elles sont inférieures à 0
prev_lm <- ifelse(prev_lm < 0, 0, prev_lm)
prev_lm <- unname(prev_lm)
```

```{r}
# Calcul du RMSE
rmse_lm <- get_rmse(y_true = dt_test[, y], y_prev = prev_lm)
rmse_lm
```
Ce modèle de régression linéaire multiple sur les retards de la production y est moins performant que le premier modèle PLS prenant en compte uniquement les retards de la production y :  RMSE PLS : 273.5126 < 276.6974 : RMSE RegLin.

```{r}
# Concaténer les données pour dygraph
dt_prev_RegLin <- cbind(dt_test[,"date",with=FALSE], dt_test[,"y",with=FALSE], prev_lm)
colnames(dt_prev_RegLin) <- c("date", "y_true", "y_prev")

# Convertir la date en format de date R
# dt_prev_RegLin$date <- as.Date(dt_prev_RegLin$date)

# Afficher le graphique dygraph
dygraphs::dygraph(data = dt_prev_RegLin, main = "Régression linéaire - Production") %>%
  dygraphs::dySeries(name = "y_true", color = "green")%>%
  dygraphs::dySeries(name = "y_prev", color = "red")
```



### ARIMA

-   Implémenter un modèle type ARIMA. Comparez-le aux modèles PLS et LS.
-   Référence :
    -   [Pour formater les données ;](https://essicolo.github.io/ecologie-mathematique-R/chapitre-temps.html#m%C3%A9thode-ses)
    -   [Pour le modèle.](https://essicolo.github.io/ecologie-mathematique-R/chapitre-temps.html#la-m%C3%A9thode-arima)

#### Preprocessing et Data Visualisation

```{r}
# Import des données
dt <- readRDS("./data.RDS")
dt <- dt[seq(dim(dt)[1],1),]
#On lisse le modèle : si y=0 on fait la moyenne de la valeur précédente et de la valeur qui suit
for (i in (1:dim(dt)[1])) {
  if (dt[i,2] == 0) {
    dt[i,2] <- (dt [i-1,2] + dt[i+1,2])/2
  }
}
#On divise notre dataset en TRAIN/TEST
dt_train <- dt[year(date) <= 2022]
dt_test <- dt[year(date) > 2022]
dt_train
```

```{r}
#Statistique descriptive de notre échantillon de train
summary(dt_train)
```

```{r}
#Les 7 bonnes prédictions
xm.source_test_7 <- zoo(dt_test[[2]])[1:7]
xm.source_test_7
summary(xm.source_test_7)
plot(xm.source_test_7)
```

```{r}
#Les 7 bonnes prédictions avec lag
LAG=30
xm.source_test_7_lag <- zoo(dt[[2]])
desaison_test_7_lag <- xm.source_test_7_lag-lag(xm.source_test_7_lag,-LAG)
desaison_test_7_lag <- desaison_test_7_lag[523:530]
desaison_test_7_lag
summary(desaison_test_7_lag)
plot(desaison_test_7_lag)
```

```{r}
#On met l'échantillon de train dans le format zoo et on plot:
xm.source <- zoo(dt_train[[2]])
xm.source_vrai <- zoo(dt[[2]])
xm <- xm.source
plot(xm)

```

```{r}
#Test de racine unitaire : Augmented Dickey-Füller
adf <- adfTest(xm, lag=0, type="nc") #
adf
#Souhait: <0.05 H0 : rho =1
#Il y a une racine unitaire
```


#### Une première approche avec un auto_arima sur la série brute

```{r}
#Une première approche avec une fonction qui exhibe de manière "black-box" le modèle ARIMA
fit <- auto.arima(xm)

dt_arima <- copy(dt)
for (i in (1:dim(dt_arima)[1])) {
  dt_arima[i,2] <- NaN
  
}
for (i in (1:length(as.numeric(forecast(fit,h=20)$mean)))) {
  dt_arima[518 +i,2] <- as.numeric(forecast(fit,h=20)$mean)[[i]]
  
}
names(dt_arima)[names(dt_arima) == 'y'] <- 'y_arima'
```

```{r}
Graph <- cbind(dt[dt$date >= "2022-12-15" & dt$date <= "2023-02-01", ][,-3], dt_arima[dt_arima$date >= "2022-12-15" & dt_arima$date <= "2023-02-01", ][,-3])
dygraph(Graph, main = "Prévision VS Labels modèle Black-Box")%>%
  dySeries("y", label = "Label") %>%
  dySeries("y_arima", label = "Prev") 
```

```{r}
plot(forecast(fit,h=20),xlim = c(450, 550))
```

```{r}
#Le modèle ainsi trouvé : c'est plus que critiquable !
fit
```

```{r}
rmse_init <- get_rmse(y_true = xm.source_test_7,
                      y_prev = as.numeric(forecast(fit,h=7)$mean))
rmse_init
```

```{r}
#Autocorrélation de notre série:
par(mfrow=c(1,2)) #
acf(xm, lag.max = 600) #
axis(side=1,at=seq(0,600,50)) #
acf(xm, lag.max = 55) #
axis(side=1,at=seq(0,55,5)) #
#On prend q = 50
```

```{r}
#Autocorrélation partielle de notre série
par(mfrow=c(1,2)) #
pacf(xm, lag.max = 600) #
axis(side=1,at=seq(0,600,50))
pacf(xm, lag.max = 20) #
axis(side=1,at=seq(0,20,5))
#On prend p=4
```

#### Une seconde approche avec un auto_arima sur la série laggée de 30 jours


```{r}
#On essaie de soustraire l'effet mensuel
LAG=30
desaison <- xm-lag(xm,-LAG) #
desaison <- desaison - mean(desaison)
summary(desaison)
plot(desaison)
```

```{r}
adf <- adfTest(desaison, lag=0, type="nc") #
adf
#Souhait: <0.05 H0 : rho =1
#Il n'y a plus une racine unitaire
```

```{r}
#Autocorrélation de notre série avec lag:
par(mfrow=c(1,2)) #
acf(desaison, lag.max = 600) #
axis(side=1,at=seq(0,600,50)) #
acf(desaison, lag.max = 23) #
axis(side=1,at=seq(0,23,5)) #
#On prend q=20
```

```{r}
#Autocorrélation partielle de notre série
par(mfrow=c(1,2)) #
pacf(desaison, lag.max = 600) #
axis(side=1,at=seq(0,600,50))
pacf(desaison, lag.max = 10) #
axis(side=1,at=seq(0,10,1))
#On prend p=5
```

```{r}
#Modèle "Black-Box" sur cette série sans effet mensuel :
#Une première approche avec une fonction qui exhibe de manière "black-box" le modèle ARIMA
fit <- auto.arima(desaison)
xm.source_vrai <- zoo(dt[[2]])
desaison_vrai <- xm.source_vrai-lag(xm.source_vrai,-LAG) #

dt_arima <- copy(dt)
for (i in (1:dim(dt_arima)[1])) {
  dt_arima[i,2] <- NaN
  
}
for (i in (1:length(as.numeric(forecast(fit,h=20)$mean)))) {
  dt_arima[518 +i,2] <- as.numeric(forecast(fit,h=20)$mean)[[i]]
  
}
names(dt_arima)[names(dt_arima) == 'y'] <- 'y_arima'

dt_lag <-copy(dt)
for (i in (1:dim(dt_lag)[1])) {
  dt_lag[i,2] <- desaison_vrai[i]
  
}
```

```{r}
Graph <- cbind(dt_lag[dt_lag$date >= "2022-12-15" & dt_lag$date <= "2023-02-01", ][,-3], dt_arima[dt_arima$date >= "2022-12-15" & dt_arima$date <= "2023-02-01", ][,-3])
dygraph(Graph, main = paste("Prévision VS Labels modèle Black-Box avec LAG= ",toString(LAG)))%>%
  dySeries("y", label = "Label") %>%
  dySeries("y_arima", label = "Prev") 
```

```{r}
fit
```

```{r}
rmse_init <- get_rmse(y_true = desaison_test_7_lag,
                      y_prev = as.numeric(forecast(fit,h=7)$mean))
rmse_init
```

#### Test de Stationnarité de la série brute/laggée


```{r}
#### Q4 ####
#Hypothèse nulle : la série a une racine sur le cercle unité / H1: Stationarité
pp.test(xm) #
#On veut une p-valeur inférieure à 0.05 : ce n'est pas le cas avec la série initiale
```

```{r}
#Hypothèse nulle : la série a une racine sur le cercle unité / H1: Stationarité
pp.test(desaison)
#On veut une p-valeur inférieure à 0.05 : c'est le cas avec la série laggée
```

#### Essais de modèle ARIMA à la main 

```{r}
#On teste un modèle arima :
arima5_0_20 <- arima(desaison,c(5,0,20)) #
arima5_0_20
```

#### Test d'hypothèses pour sélectionner les meilleurs modèles

```{r}
Box.test(arima5_0_20$residuals, lag=26, type="Ljung-Box", fitdf=5) #
#On veut p-valeur >0.05
```

```{r}
Qtests <- function(series, k, fitdf=0) {
  pvals <- apply(matrix(1:k), 1, FUN=function(l) {
    pval <- if (l<=fitdf) NA else Box.test(series, lag=l, type="Ljung-Box", fitdf=fitdf)$p.value
    return(c("lag"=l,"pval"=pval))
  })
  return(t(pvals))
}
round(Qtests(arima5_0_20$residuals,29,fitdf=5),3)
#On veut que ce soit plus grand que 0.05
```

```{r}
signif <- function(estim){ #fonction de test des significations individuelles des coefficients
  coef <- estim$coef
  se <- sqrt(diag(estim$var.coef))
  t <- coef/se
  pval <- (1-pnorm(abs(t)))*2
  return(rbind(coef,se,pval))
}

signif(arima5_0_20) #
```

```{r}
arimafit <- function(estim){
  adjust <- round(signif(estim),3)
  pvals <- Qtests(estim$residuals,30,fitdf=5)
  pvals <- matrix(apply(matrix(1:30,nrow=6),2,function(c) round(pvals[c,],3)),nrow=6)
  colnames(pvals) <- rep(c("lag", "pval"),5)
  cat("tests de nullite des coefficients :\n")
  print(adjust)
  cat("\n tests d'absence d'autocorrelation des residus : \n")
  print(pvals)
}
estim <- arima(desaison,c(5,0,20)); arimafit(estim)
```

```{r}
## fonction pour estimer un arima et en verifier l'ajustement et la validite
modelchoice <- function(p,q,data=desaison, k=24){
  estim <- try(arima(data, c(p,0,q),optim.control=list(maxit=20000)))
  if (class(estim)=="try-error") return(c("p"=p,"q"=q,"arsignif"=NA,"masignif"=NA,"resnocorr"=NA, "ok"=NA))
  arsignif <- if (p==0) NA else signif(estim)[3,p]<=0.05
  masignif <- if (q==0) NA else signif(estim)[3,p+q]<=0.05
  resnocorr <- sum(Qtests(estim$residuals,24,length(estim$coef)-1)[,2]<=0.05,na.rm=T)==0
  checks <- c(arsignif,masignif,resnocorr)
  ok <- as.numeric(sum(checks,na.rm=T)==(3-sum(is.na(checks))))
  return(c("p"=p,"q"=q,"arsignif"=arsignif,"masignif"=masignif,"resnocorr"=resnocorr,"ok"=ok))
}

## fonction pour estimer et verifier tous les arima(p,q) avec p<=pmax et q<=max
armamodelchoice <- function(pmax,qmax){
  pqs <- expand.grid(0:pmax,0:qmax)
  t(apply(matrix(1:dim(pqs)[1]),1,function(row) {
    p <- pqs[row,1]; q <- pqs[row,2]
    cat(paste0("Computing ARMA(",p,",",q,") \n"))
    modelchoice(p,q)
  }))
}

pmax<-5
qmax<-20
armamodels <- armamodelchoice(pmax,qmax) #estime tous les arima (patienter...)


selec <- armamodels[armamodels[,"ok"]==1&!is.na(armamodels[,"ok"]),] #modeles bien ajustes et valides
selec
#Nous avons trois modèles valides :
#ARMA(3,9)
#ARMA(5,19)
#ARMA(5,20)
```

```{r}
pqs <- apply(selec,1,function(row) list("p"=as.numeric(row[1]),"q"=as.numeric(row[2]))) #cree une liste des ordres p et q des modeles candidats
names(pqs) <- paste0("arma(",selec[,1],",",selec[,2],")") #renomme les elements de la liste
models <- lapply(pqs, function(pq) arima(desaison,c(pq[["p"]],0,pq[["q"]]))) #cree une liste des modeles candidats estimes
vapply(models, FUN.VALUE=numeric(2), function(m) c("AIC"=AIC(m),"BIC"=BIC(m))) #calcule les AIC et BIC des modeles candidats
### L'ARMA(5,19) minimise les criteres d'information.
```

```{r}
#ARMA(3,9) pour la prochaine semaine
rmse_init <- get_rmse(y_true = desaison_test_7_lag,
                      y_prev = as.numeric(forecast(arima(desaison, c(3,0,9)),h=7)$mean))
rmse_init
```

```{r}
#ARMA(5,19) pour la prochaine semaine
rmse_init <- get_rmse(y_true = desaison_test_7_lag,
                      y_prev = as.numeric(forecast(arima(desaison, c(5,0,19)),h=7)$mean))
rmse_init
```

```{r}
#ARMA(5,20) pour la prochaine semaine
rmse_init <- get_rmse(y_true = desaison_test_7_lag,
                      y_prev = as.numeric(forecast(arima(desaison, c(5,0,20)),h=7)$mean))
rmse_init
```

```{r}
#Modèle "A la main" sur cette série sans effet mensuel :
fit <- arima(desaison, c(5,0,19))
xm.source_vrai <- zoo(dt[[2]])
desaison_vrai <- xm.source_vrai-lag(xm.source_vrai,-LAG) #

dt_arima <- copy(dt)
for (i in (1:dim(dt_arima)[1])) {
  dt_arima[i,2] <- NaN
  
}
for (i in (1:length(as.numeric(forecast(fit,h=7)$mean)))) {
  dt_arima[518 +i,2] <- as.numeric(forecast(fit,h=7)$mean)[[i]]
  
}
names(dt_arima)[names(dt_arima) == 'y'] <- 'y_arima'

dt_lag <-copy(dt)
for (i in (1:dim(dt_lag)[1])) {
  dt_lag[i,2] <- desaison_vrai[i]
  
}
```

```{r}
Graph <- cbind(dt_lag[dt_lag$date >= "2022-12-15" & dt_lag$date <= "2023-02-01", ][,-3], dt_arima[dt_arima$date >= "2022-12-15" & dt_arima$date <= "2023-02-01", ][,-3])
dygraph(Graph, main = paste("Prévision VS Labels modèle Black-Box avec LAG= ",toString(LAG)))%>%
  dySeries("y", label = "Label") %>%
  dySeries("y_arima", label = "Prev") 
```

### Prédiction à horizon T+1 :

```{r}
#Sommes des MSE avec une prévision à t+1
#Les bonnes prédictions avec lag
LAG=30
xm.source_test_all_lag <- zoo(dt[[2]])
desaison_test_all_lag <- xm.source_test_all_lag-lag(xm.source_test_7_lag,-LAG) #
desaison_test_all_lag <- desaison_test_all_lag[523:length(xm.source_test_all_lag)]
desaison_test_all_lag
summary(desaison_test_all_lag)
plot(desaison_test_all_lag)
```

```{r}
Liste_prev_lag <- c()
LAG=30
xm.source_all_lag <- zoo(dt[[2]])
L <-length(xm.source_all_lag)
desaison_all_lag <- xm.source_all_lag-lag(xm.source_all_lag,-LAG) #
Zoo=zoo(desaison_all_lag)
for (i in (523:L)) {
  fit <- arima(Zoo[1:i], c(3,0,9))
  Liste_prev_lag<-c(Liste_prev_lag,as.numeric(forecast(fit,h=1)$mean))
}
Liste_prev_lag
```

```{r}
dt_arima <- copy(dt)
for (i in (1:dim(dt_arima)[1])) {
  dt_arima[i,2] <- NaN
  
}
for (i in (523:L)) {
  dt_arima[i,2] <- Liste_prev_lag[[i-522]]
  
}
names(dt_arima)[names(dt_arima) == 'y'] <- 'y_arima'

dt_lag <-copy(dt)
for (i in (1:dim(dt_lag)[1])) {
  dt_lag[i,2] <- desaison_vrai[i]
  
}

```

```{r}
# Crée des variables lag
lag_names <- paste0("y_lag_", 1:4)
dt_prev <- copy(dt)

LAG=30
X <- zoo(dt_prev[[2]])
X_lag <- X-lag(X,-LAG) #

for (i in (1:length(dt_prev[[2]]))) {
  dt_prev[i,2] <- X_lag[i]
  
}

dt_prev[, c(lag_names) := shift(x = y, n = 1:4, type = "lag")]
dt_prev <- na.omit(dt_prev)

# On calcule les prévisions
dt_prev[, prev := rowMeans(.SD), .SDcols = lag_names]

# Prévision
dt_init_prev <- dt_prev[year(date) <= 2022, prev := NA]

LAG=30
xm.source_all_lag <- zoo(dt_init_prev[[8]])
desaison_all_lag <- xm.source_all_lag-lag(xm.source_all_lag,-LAG) #
```



```{r}
Graph <- cbind(dt_lag[dt_lag$date >= "2022-12-15" & dt_lag$date <= "2023-02-12", ][,-3], dt_arima[dt_arima$date >= "2022-12-15" & dt_arima$date <= "2023-02-12", ][,-3],dt_init_prev[dt_init_prev$date >= "2022-12-15" & dt_init_prev$date <= "2023-02-12", ][,8])
dygraph(Graph, main = paste("Prévision VS Labels modèle Black-Box avec LAG= ",toString(LAG)))%>%
  dySeries("y", label = "Label") %>%
  dySeries("y_arima", label = "Prev") %>%
  dySeries("prev", label = "Prev_EDF")

```

```{r}
#EDF avec t+1
rmse_init <- get_rmse(y_true = desaison_test_all_lag[ !is.na(desaison_test_all_lag), desaison_test_all_lag],
                      y_prev = dt_init_prev[ !is.na(prev), prev])
rmse_init
```

```{r}
#ARMA(3,9) avec t+1
rmse_init <- get_rmse(y_true = desaison_test_all_lag[ !is.na(desaison_test_all_lag), desaison_test_all_lag],
                      y_prev = Liste_prev_lag)
rmse_init
```

```{r}
#Vraies valeurs
desaison_test_all_lag[ !is.na(desaison_test_all_lag), desaison_test_all_lag]
```

```{r}
#Notre modèle
Liste_prev_lag
```

```{r}
#EDF
dt_init_prev[ !is.na(prev), prev]
```

### Modèle ML

# Implémentation d'une Random Forest pour faire une régression


```{r}
#On installe le package en conséquence
install.packages("randomForest")
library(randomForest)
```
```{r}
#On fit le modèle
rf = randomForest(y ~ date + x, data = dt_train)
rf
```

```{r}
#On calcule note MSE sur notre échantillon de TRAIN
rmse_init <- get_rmse(y_true = dt_train$y,
                      y_prev = predict(rf, newdata = dt_train))
rmse_init
```
```{r}
#On calcuke notre MSE sur notre échantillon de TEST
rmse_init <- get_rmse(y_true = dt_test$y,
                      y_prev = predict(rf, newdata = dt_test))
rmse_init
#On overfit !
```
```{r}
#On établit la liste de nos prédictions
Liste_prev_ML <- c()
xm.source_ML <- zoo(dt[[2]])
L <-length(xm.source_ML)
Zoo=zoo(xm.source_ML)
for (i in (522:L)) {
  rf <- randomForest(y ~ date + x, data = dt[-(i:length(dt[[1]])),])
  Liste_prev_ML<-c(Liste_prev_ML, tail(predict(rf, newdata = dt[-(i+1:length(dt_lag[[1]])),]), n=1))
}
Liste_prev_ML
```


```{r}
#On prépare le dataframe pour le plot
dt_ML <- copy(dt)
for (i in (1:dim(dt_ML)[1])) {
  dt_ML[i,2] <- NaN
  
}
for (i in (522:L)) {
  dt_ML[i,2] <- Liste_prev_ML[[i-521]]
  
}
names(dt_ML)[names(dt_ML) == 'y'] <- 'y_ML'
```

```{r}
#On plot
Graph <- cbind(dt[dt$date >= "2022-12-15", ][,-3], dt_ML[dt_ML$date >= "2022-12-15", ][,-3])
dygraph(Graph, main = paste("Prévision VS Labels modèle ML"))%>%
  dySeries("y", label = "Label") %>%
  dySeries("y_ML", label = "ML") 
#C'est moins bien que le modèle ARIMA : c'est normal, on ne prend pas en compte l'aspect temporel de nos données !

```
```{r}
#MSE sur 2023
rmse_init <- get_rmse(y_true = dt[year(date) > 2022]$y,
                      y_prev = dt_ML[year(date) > 2022]$y)
rmse_init
```

```{r}
#On réessaye en laggant notre jeu de données
dt_lag <- dt_lag[-(532:length(dt_lag[[1]])),]
```


```{r}
rf = randomForest(y ~ date + x, data = dt_lag[year(date) <= 2022])
```

```{r}
rmse_init <- get_rmse(y_true = dt_lag[year(date) <= 2022]$y,
                      y_prev = predict(rf, newdata = dt_lag[year(date) <= 2022]))
rmse_init
#C'est moins bien sur le TRAIN SET
```

```{r}
rmse_init <- get_rmse(y_true = dt_lag[year(date) > 2022]$y,
                      y_prev = predict(rf, newdata = dt_lag[year(date) > 2022]))
rmse_init
#C'est moins bien sur le TEST SET
```
