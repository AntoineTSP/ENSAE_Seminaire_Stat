---
title: "[ENSAE, 2A] Séminaire statistique 2023"
author: "Hassan Maissoro/ Léa Joly / Antoine Klein"
output: 
  html_document:
    toc : true
    toc_depth : 4
    number_sections: true
    theme: readable
    highlight: tango
    toc_float:
      collapsed: false
      smooth_scroll: false
    css: style.css
    fig_width: 8
    fig_height: 3
date: "2023-03-17"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

```{r}
install.packages("manipulateWidget")
install.packages("tseries")
install.packages("zoo")
install.packages("dygraphs")
install.packages('pls')
install.packages("forecast", dependencies = TRUE)
install.packages("ggplot2")
```


<p id = "p_"><b> Sujet : modélisation de la production d'électricité d'un barrage </b></p>
```{r}
library(data.table)
library(magrittr)
library(dygraphs)
library(manipulateWidget)
library(pls)
require(zoo) #format de serie temporelle pratique et facile d'utilisation (mais plus volumineux)
require(tseries) #diverses fonctions sur les series temporelles
library(forecast)
library(ggplot2)
```



# Données

Les données utilisées dans le cadre de ce séminaire ont été simulées.
On se concentre sur un seul barrage hydroélectrique.
 
- `date` : date d'observation de la mesure.
- `y` : production électrique du barrage.
- `x` : hauteur du cours sur lequel est implanté le barrage, mesurée par une station placée en amont du barrage.

```{r fig.width=8, fig.height=5, fig.align='center'}
#On change le path
path <- "~/work/ENSAE_Seminaire_Stat"
setwd(path) #definit l'espace de travail (working directory ou "wd")
getwd() #affiche le wd
# Import des données
dt <- readRDS("./data.RDS")

# Visualisation
gy <- dygraph(data = dt[, .(date, y)],main = "Production électrique",
              xlab = "date", ylab = "y", group = "rowData") %>% 
  dyOptions(colors = "blue")
gx <- dygraph(data = dt[, .(date, x)],main = "Hauteur du cours d'eau",
              xlab = "date", ylab = "x", group = "rowData")%>% 
  dyOptions(colors = "green")

manipulateWidget::combineWidgets(list = list(gy, gx), nrow = 2)
```


**Remaque :**

- Les chutes de la production vers `0`. On ne sait pas exactement pourquoi.
    * Barrage en non actif ?
    * Est-ce qu'on peut les modéliser ?
- Les piques de la hauteur du cours d'eau sont observés pendant l'hiver.

# Modélisation
 
*Objectif :* améliorer la méthode initiale.

*Questions :*

- comment faire un découpage train/test lorsque les données sont temporelles ?
- comment faire une validation croisée sur des séries temporelles ?

*Choix du coupage train/test :*
```{r}
dt[, range(date)]
```

- train sur 2021 - 2022 ;
- test sur 2023.

*Horizon de prévision :* on se concentre sur l'horizon : **J+1**.

*Mesure d'erreur de prévision : *
```{r}
get_rmse <- function(y_true, y_prev){
  sqrt(mean( (y_true - y_prev) ** 2 ))
}
```


## Méthode à améliorer

La méthode initialement implémentée consiste à faire la moyenne des 4 derniers jours.

```{r}
# Crée des variables lag
lag_names <- paste0("y_lag_", 1:4)
dt_prev <- copy(dt)

dt_prev[, c(lag_names) := shift(x = y, n = 1:4, type = "lag")]
dt_prev <- na.omit(dt_prev)

# On calcule les prévisions
dt_prev[, prev := rowMeans(.SD), .SDcols = lag_names]

# Prévision
dt_init_prev <- dt_prev[year(date) <= 2022, prev := NA]
```

```{r}
rmse_init <- get_rmse(y_true = dt_init_prev[ !is.na(prev), y],
                      y_prev = dt_init_prev[ !is.na(prev), prev])
rmse_init
```

```{r fig.width=8, fig.height=3, fig.align='center'}
dygraphs::dygraph(data = dt_init_prev[, .(date, y, prev)], main = "prev vs true") %>% 
  dygraphs::dySeries(name = "prev", color = "red")
```

- Analysez le graphique ci-dessus.

## Améliorations

### Ajout de covariables

Les covariables peuvent être des :
 
- retards de `y` ;
- retards de `x` ;
- agrégats de retards `y` et/ou de `x`.

```{r}
## Ajout de lag de x et de y
dt_model <- copy(dt)
dt_model[, c(paste0("y_lag_", 1:14)) := shift(x = y, n = 1:14, type = "lag")]
dt_model[, c(paste0("x_lag_", 1:14)) := shift(x = x, n = 1:14, type = "lag")]
dt_model <- na.omit(dt_model)
```

```{r}
dt_train <- dt_model[year(date) <= 2022]
dt_test <- dt_model[year(date) > 2022]
```

### PLS 

Régression des moindres carrés partiels (PLS). Le nombre de composantes à conserver est déterminé par validation croisée sur les données d’apprentissage. Référence : [cliquer ici](https://www.math.univ-toulouse.fr/~besse/Wikistat/pdf/st-m-app-sparse-pls.pdf) ;

- PLS que sur les retards de la production `y` ;

```{r}
ylag <- paste0("y_lag_", 1:14)

## Estimation du modèle
pls_prod <- pls::plsr(formula = y ~ .,
                      data = dt_train[, .SD, .SDcols = c("y", ylag)],
                      validation = "CV")
## Take optimal ncomp
rmsepcv.pls <- pls::MSEP(pls_prod, estimate = 'CV')
ncp.optim <- which.min(rmsepcv.pls$val["CV", , ]) - 1
ncp.optim <- ifelse(ncp.optim == 0, 1, ncp.optim)

# prevision
prev_pls <- predict(object = pls_prod, newdata = dt_test, ncomp = ncp.optim)

## On borne les prévisions si elles sont inférieures à 0
prev_pls <- ifelse(prev_pls[, 1, 1] < 0, 0, prev_pls[, 1, 1])
prev_pls <- unname(prev_pls)
```

```{r}
rmse_pls <- get_rmse(y_true = dt_test[, y], y_prev = prev_pls)
rmse_pls
```

```{r fig.width=8, fig.height=3, fig.align='center'}
dt_prev_pls <- rbind(
  copy(dt_test)[, .(date, y)][, prev_pls := prev_pls],
  copy(dt_train)[, .(date, y)][, prev_pls := NA]
)

dygraphs::dygraph(data = dt_prev_pls, main = "PLS - prev vs true") %>% 
  dygraphs::dySeries(name = "prev_pls", color = "red")
```


*TO DO : *
 
- Comparez ce rmse à celui de la prévision initiale ;
- Ajoutez les covariables en `x_` dans le modèle. Est-ce qu'il y a une amélioration ? Pourquoi ?
- Créez d'autres agrégats de lags et ajoutez les au modèle. Est-ce qu'il y a une amélioration ?

### LS
 
- Implémenter une régression linéaire. Comparez-là à votre meilleur modèle PLS ?
- Référence : [cliquez ici.](https://bookdown.org/evraloui/lbira2110/modeles-lineaires.html)

### ARIMA
 
- Implémenter un modèle type ARIMA. Comparez-le aux modèles PLS et LS.
- Référence : 
    * [Pour formater les données ;](https://essicolo.github.io/ecologie-mathematique-R/chapitre-temps.html#m%C3%A9thode-ses)
    * [Pour le modèle.](https://essicolo.github.io/ecologie-mathematique-R/chapitre-temps.html#la-m%C3%A9thode-arima)

```{r}
# Import des données
dt <- readRDS("./data.RDS")
dt <- dt[seq(dim(dt)[1],1),]
#On lisse le modèle : si y=0 on prend la valeur précédente
for (i in (1:dim(dt)[1])) {
  if (dt[i,2] == 0) {
    dt[i,2] <- (dt [i-1,2] + dt[i+1,2])/2
  }
}
dt_train <- dt[year(date) <= 2022]
dt_test <- dt[year(date) > 2022]
dt_train
```

```{r}
#Statistique descriptive de notre échantillon de train
summary(dt_train)
```

```{r}
xm.source <- zoo(dt_train[[2]]) #convertit le premier element de data en serie temporelle de type "zoo"
xm.source_vrai <- zoo(dt[[2]])
T <- length(xm.source)
xm <- xm.source[1:(T-4)] #supprime les 4 dernieres valeurs
plot(xm)

```

```{r}
#Une première approche avec une fonction qui exhibe de manière "black-box" le modèle ARIMA
fit <- auto.arima(xm)

dt_arima <- copy(dt)
for (i in (1:dim(dt_arima)[1])) {
  dt_arima[i,2] <- NaN
  
}
for (i in (1:length(as.numeric(forecast(fit,h=20)$mean)))) {
  dt_arima[518 +i,2] <- as.numeric(forecast(fit,h=20)$mean)[[i]]
  
}
names(dt_arima)[names(dt_arima) == 'y'] <- 'y_arima'
```


```{r}
Graph <- cbind(dt[dt$date >= "2022-12-15" & dt$date <= "2023-02-01", ][,-3], dt_arima[dt_arima$date >= "2022-12-15" & dt_arima$date <= "2023-02-01", ][,-3])
dygraph(Graph, main = "Prévision VS Labels modèle Black-Box")%>%
  dySeries("y", label = "Label") %>%
  dySeries("y_arima", label = "Prev") 
```



```{r}
plot(forecast(fit,h=20))
```

```{r}
#Le modèle ainsi trouvé : c'est plus que critiquable !
fit
```



```{r}
#Autocorrélation de notre série:
par(mfrow=c(1,2)) #
acf(xm, lag.max = 600) #
axis(side=1,at=seq(0,600,50)) #
acf(xm, lag.max = 55) #
axis(side=1,at=seq(0,55,5)) #
#On prend q = 50
```

```{r}
#Autocorrélation partielle de notre série
par(mfrow=c(1,2)) #
pacf(xm, lag.max = 600) #
axis(side=1,at=seq(0,600,50))
pacf(xm, lag.max = 20) #
axis(side=1,at=seq(0,20,5))
#On prend p=4
```


```{r}
#On essaie de soustraire l'effet mensuel
LAG=30
desaison <- xm-lag(xm,-LAG) #
desaison <- desaison - mean(desaison)
summary(desaison)
plot(desaison)
```
```{r}
#Autocorrélation de notre série avec lag:
par(mfrow=c(1,2)) #
acf(desaison, lag.max = 600) #
axis(side=1,at=seq(0,600,50)) #
acf(desaison, lag.max = 23) #
axis(side=1,at=seq(0,23,5)) #
#On prend q=20
```


```{r}
#Autocorrélation partielle de notre série
par(mfrow=c(1,2)) #
pacf(desaison, lag.max = 600) #
axis(side=1,at=seq(0,600,50))
pacf(desaison, lag.max = 10) #
axis(side=1,at=seq(0,10,1))
#On prend p=5
```



```{r}
#Modèle "Black-Box" sur cette série sans effet mensuel :
#Une première approche avec une fonction qui exhibe de manière "black-box" le modèle ARIMA
fit <- auto.arima(desaison)
xm.source_vrai <- zoo(dt[[2]])
desaison_vrai <- xm.source_vrai-lag(xm.source_vrai,-LAG) #

dt_arima <- copy(dt)
for (i in (1:dim(dt_arima)[1])) {
  dt_arima[i,2] <- NaN
  
}
for (i in (1:length(as.numeric(forecast(fit,h=20)$mean)))) {
  dt_arima[518 +i,2] <- as.numeric(forecast(fit,h=20)$mean)[[i]]
  
}
names(dt_arima)[names(dt_arima) == 'y'] <- 'y_arima'

dt_lag <-copy(dt)
for (i in (1:dim(dt_lag)[1])) {
  dt_lag[i,2] <- desaison_vrai[i]
  
}
```

```{r}
Graph <- cbind(dt_lag[dt_lag$date >= "2022-12-15" & dt_lag$date <= "2023-02-01", ][,-3], dt_arima[dt_arima$date >= "2022-12-15" & dt_arima$date <= "2023-02-01", ][,-3])
dygraph(Graph, main = paste("Prévision VS Labels modèle Black-Box avec LAG= ",toString(LAG)))%>%
  dySeries("y", label = "Label") %>%
  dySeries("y_arima", label = "Prev") 
```

```{r}
fit
```


```{r}
#### Q4 ####
#Hypothèse nulle : la série a une racine sur le cercle unité / H1: Stationarité
pp.test(xm) #
#On veut une p-valeur inférieure à 0.05 : ce n'est pas le cas avec la série initiale
```

```{r}
#Hypothèse nulle : la série a une racine sur le cercle unité / H1: Stationarité
pp.test(desaison)
```


```{r}
#On teste un modèle arima :
arima5_0_20 <- arima(desaison,c(5,0,20)) #
arima5_0_20
```
```{r}
Box.test(arima5_0_20$residuals, lag=26, type="Ljung-Box", fitdf=5) #
#On veut p-valeur >0.05
```
```{r}
Qtests <- function(series, k, fitdf=0) {
  pvals <- apply(matrix(1:k), 1, FUN=function(l) {
    pval <- if (l<=fitdf) NA else Box.test(series, lag=l, type="Ljung-Box", fitdf=fitdf)$p.value
    return(c("lag"=l,"pval"=pval))
  })
  return(t(pvals))
}
round(Qtests(arima5_0_20$residuals,29,fitdf=5),3)
#On veut que ce soit plus grand que 0.05
```

```{r}
signif <- function(estim){ #fonction de test des significations individuelles des coefficients
  coef <- estim$coef
  se <- sqrt(diag(estim$var.coef))
  t <- coef/se
  pval <- (1-pnorm(abs(t)))*2
  return(rbind(coef,se,pval))
}

signif(arima5_0_20) #
```
```{r}
arimafit <- function(estim){
  adjust <- round(signif(estim),3)
  pvals <- Qtests(estim$residuals,24,length(estim$coef)-1)
  pvals <- matrix(apply(matrix(1:24,nrow=6),2,function(c) round(pvals[c,],3)),nrow=6)
  colnames(pvals) <- rep(c("lag", "pval"),4)
  cat("tests de nullite des coefficients :\n")
  print(adjust)
  cat("\n tests d'absence d'autocorrelation des residus : \n")
  print(pvals)
}
estim <- arima(desaison,c(5,0,20)); arimafit(estim)
```
```{r}
## fonction pour estimer un arima et en verifier l'ajustement et la validite
modelchoice <- function(p,q,data=r, k=24){
  estim <- try(arima(data, c(p,0,q),optim.control=list(maxit=20000)))
  if (class(estim)=="try-error") return(c("p"=p,"q"=q,"arsignif"=NA,"masignif"=NA,"resnocorr"=NA, "ok"=NA))
  arsignif <- if (p==0) NA else signif(estim)[3,p]<=0.05
  masignif <- if (q==0) NA else signif(estim)[3,p+q]<=0.05
  resnocorr <- sum(Qtests(estim$residuals,24,length(estim$coef)-1)[,2]<=0.05,na.rm=T)==0
  checks <- c(arsignif,masignif,resnocorr)
  ok <- as.numeric(sum(checks,na.rm=T)==(3-sum(is.na(checks))))
  return(c("p"=p,"q"=q,"arsignif"=arsignif,"masignif"=masignif,"resnocorr"=resnocorr,"ok"=ok))
}

## fonction pour estimer et verifier tous les arima(p,q) avec p<=pmax et q<=max
armamodelchoice <- function(pmax,qmax){
  pqs <- expand.grid(0:pmax,0:qmax)
  t(apply(matrix(1:dim(pqs)[1]),1,function(row) {
    p <- pqs[row,1]; q <- pqs[row,2]
    cat(paste0("Computing ARMA(",p,",",q,") \n"))
    modelchoice(p,q)
  }))
}

armamodels <- armamodelchoice(pmax,qmax) #estime tous les arima (patienter...)


selec <- armamodels[armamodels[,"ok"]==1&!is.na(armamodels[,"ok"]),] #modeles bien ajustes et valides
selec
```

    
### Modèle ML
 
- Implémenter un modèle de Machine Learning de votre choix. Comparez-le aux modèles PLS, LS et ARIMA.
- Référence : [voici une indication.](https://topepo.github.io/caret/).

### Lien entre `y` et `x`
 
- Est-ce que `x` apporte une information sur la prévision de `y` ?

 









